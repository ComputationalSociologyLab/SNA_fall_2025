dev.off()
#This code is the same as above, and is just used to generate the plot within the generated html file.
plot(club_net96, main = "layout_with_lgl", layout = layout_with_lgl)
plot(club_net96, main = "layout_with_fr", layout = layout_with_fr)
std_weight <- sd(E(club_net96)$weight)
weight_mean_center <- (E(club_net96)$weight - mean(E(club_net96)$weight))
recode_weight <- E(club_net96)$weight
recode_weight[weight_mean_center <= 0] <- -1
recode_weight[(weight_mean_center > 0) & (weight_mean_center <= std_weight)] <- .5
recode_weight[(weight_mean_center > std_weight) &
(weight_mean_center <= std_weight * 2)] <- 1.5
recode_weight[weight_mean_center > std_weight * 2] <- 2.5
E(club_net96)$color <- rgb(.5, .5, 0, .2)
E(club_net96)$width <- recode_weight
V(club_net96)$size <- 3
plot(club_net96, layout = layout_with_lgl)
weights <- E(club_net96)$weight
scaled_weights <- weights / sd(weights)
invscaled_weights <- 1 / scaled_weights
deg_normalweights <- strength(club_net96, mode = "all")
deg_scaledweights <- strength(club_net96, mode = "all",
weights = scaled_weights)
deg_data <- data.frame(deg_normalweights, deg_scaledweights)
deg_data[1:10, ]
deg_noweight <- degree(club_net96, mode = "all")
cor(deg_scaledweights, deg_noweight)
close_invweights <- closeness(club_net96, weights = invscaled_weights)
close_weights <- closeness(club_net96, weights = scaled_weights)
cor(deg_normalweights, close_invweights)
cor(deg_normalweights, close_weights)
deg_top10 <- order(deg_scaledweights, decreasing = T)[1:10]
toptenclubs_degree <- club_names[deg_top10]
data.frame(high_degree = toptenclubs_degree)
deg_bottom10 <- order(deg_scaledweights, decreasing = F)[1:10]
bottomtenclubs_degree <- club_names[deg_bottom10]
data.frame(high_degree = toptenclubs_degree,
low_degree = bottomtenclubs_degree)
club_profile <- factor(V(club_net96)$club_profile, ordered = T,
levels = c("low", "moderate", "high", "very_high"))
centrality_data <- data.frame(deg_data, club_profile = club_profile)
head(centrality_data)
aggregate(deg_scaledweights ~ club_profile, data = centrality_data, FUN = mean)
aggregate(deg_scaledweights  ~ club_profile, data = centrality_data, FUN = sd)
groups_scaledweights <- cluster_fast_greedy(club_net96,
weights = scaled_weights)
group_dat <- data.frame(group = as.numeric(membership(groups_scaledweights)),
name = V(club_net96)$name,
club_type_detailed = V(club_net96)$club_type_detailed)
head(group_dat)
group_dat[group_dat[, "group"] == 1, ]
prop.table(table(group_dat$club_type_detailed[group_dat$group == 1]))
group_dat[group_dat[, "group"] == 2, ]
prop.table(table(group_dat$club_type_detailed[group_dat$group == 2]))
group_dat[group_dat[, "group"] == 3, ]
prop.table(table(group_dat$club_type_detailed[group_dat$group == 3]))
group_dat[group_dat[, "group"] == 4, ]
prop.table(table(group_dat$club_type_detailed[group_dat$group == 4]))
group_dat[group_dat[, "group"] == 5,]
prop.table(table(group_dat$club_type_detailed[group_dat$group == 5]))
V(club_net96)$color <- membership(groups_scaledweights)
V(club_net96)$frame.color[deg_top10] <- rgb(1, 0, 0, .75)
set.seed(105)
group_label <- group_dat$group
plot(club_net96, main = "Coloring by Groups",
vertex.label = group_label, vertex.label.cex = .75)
library(tnet)
club_edgelist96 <- as_edgelist(graph = club_net96, names = F)
club_edgelist96 <- cbind(club_edgelist96, scaled_weights)
colnames(club_edgelist96) <- c("sender", "receiver", "weights")
club_edgelist96 <- rbind(club_edgelist96, club_edgelist96[, c(2, 1, 3)])
head(club_edgelist96)
dim(club_edgelist96)
degree_alpha1 <- degree_w(net = club_edgelist96, measure = "alpha",
type = "out", alpha = 1)
head(degree_alpha1)
degree_alpha0 <- degree_w(net = club_edgelist96, measure = "alpha",
type = "out", alpha = 0)
head(degree_alpha0)
degree_alpha.5 <- degree_w(net = club_edgelist96, measure="alpha",
type = "out", alpha = .5)
cor(degree_alpha1[, 2], degree_alpha.5[, 2])
cor(degree_alpha0[, 2], degree_alpha.5[, 2])
close_alpha1 <- closeness_w(net = club_edgelist96, alpha = 1)
head(close_alpha1)
close_alpha0 <- closeness_w(club_edgelist96, alpha = 0)
head(close_alpha0)
close_igraph_noweight <- closeness(club_net96, weights = NA)
head(close_igraph_noweight)
close_alpha.5 <- closeness_w(club_edgelist96, alpha = .5)
cor(close_alpha0[, 2], close_alpha.5[, 2])
student_net96 <- onemode96$proj1
student_edges <- as_edgelist(graph = student_net96)
student_edges <- data.frame(student_edges, weight = E(student_net96)$weight)
colnames(student_edges)[1:2] <- c("sender", "receiver")
head(student_edges)
race_dat <- data.frame(name = V(student_net96)$name,
race = V(student_net96)$race)
head(race_dat)
sender_race <- race_dat[match(student_edges[, "sender"],
race_dat[, "name"]), "race"]
receiver_race <- race_dat[match(student_edges[, "receiver"],
race_dat[, "name"]), "race"]
student_edges <- data.frame(student_edges, sender_race, receiver_race)
head(student_edges)
same_race <- student_edges[, "sender_race"] == student_edges[, "receiver_race"]
sum(student_edges[same_race == T, "weight"]) / sum(student_edges[, "weight"])
club_student_edges <- as_edgelist(graph = affil_net96, names = F)
colnames(club_student_edges)[1:2] <- c("sender", "receiver")
head(club_student_edges)
race2 <- V(affil_net96)$race
match_race <- NA
for (i in 1:nrow(club_student_edges)){
# grabbing race of student in edge:
send_race <- race2[club_student_edges[i, "sender"]]
# getting race of students in club of interest, excluding student in edge:
club_id <- club_student_edges[i, "receiver"]
edges_to_club <- club_student_edges[-i, "receiver"] == club_id
student_ids <- club_student_edges[-i, ][edges_to_club, "sender"]
club_race_composition <- race2[student_ids]
# asking if race of focal student race matches any other student in club:
match_race[i] <- send_race %in% club_race_composition
}
head(match_race)
prop.table(table(match_race))
student_id_list <- apply(affiliations96_nomiss, MARGIN = 2,
FUN = function(x) which(x == 1))
student_id_list[1:2]
prop_same_func <- function(attribute, ids){
#Arguments:
#attribute: vector of attributes
#ids: ids of nodes
# subset attributes to just students in club of interest
club_subset <- attribute[ids]
# calculate number in each category
tab_attribute <- table(club_subset)
# calculate number of students in club
num_students <- sum(tab_attribute)
# calculate number of pairs that match; accomplished
# by squaring and summing the number in each category
# while also adjusting for diagonal,
# as we do not want to count the number of
# times i matches with self
num_match <- sum(tab_attribute ^ 2) - num_students
# now calculating proportion that match, by dividing
# number that match by total number of pairs, excluding
# diagonal (where i is the same student)
prop_same <- num_match / (num_students * (num_students - 1))
}
gender <- V(affil_net96)$gender[V(affil_net96)$type == FALSE]
same_gender_prop <- lapply(student_id_list, FUN = prop_same_func,
attribute = gender)
same_gender_prop <- unlist(same_gender_prop)
head(same_gender_prop)
cor(deg_normalweights, same_gender_prop)
grade <- V(affil_net96)$grade96[V(affil_net96)$type == FALSE]
same_grade_prop <- lapply(student_id_list, FUN = prop_same_func,
attribute = grade)
same_grade_prop <- unlist(same_grade_prop)
cor(deg_normalweights, same_grade_prop)
library(NLP)
library(tm)
library(SnowballC)
library(topicmodels)
library(ldatuning)
url1 <- "https://github.com/JeffreyAlanSmith/Integrated_Network_Science/raw/master/data/sociologysample.csv"
abstracts <- read.csv(file = url1, stringsAsFactors = FALSE)
str(abstracts)
abstracts[1, "text"]
abstracts_corp <- Corpus(VectorSource(abstracts$text))
length(abstracts_corp)
abstracts_corp <- tm_map(abstracts_corp, tolower)
abstracts_corp[[1]]$content
gsub_function <- function(x, pattern) gsub(pattern, replacement = " ", x)
split_words <- content_transformer(gsub_function)
abstracts_corp <- tm_map(abstracts_corp, split_words, pattern = "_")
abstracts_corp[[1]]$content
abstracts_corp <- tm_map(abstracts_corp, split_words, pattern = "/")
abstracts_corp <- tm_map(abstracts_corp, removePunctuation)
abstracts_corp <- tm_map(abstracts_corp, removeNumbers)
stopwords("english")
abstracts_corp <- tm_map(abstracts_corp, removeWords, stopwords("english"))
myStopwords <- c("dissertation", "chapter", "chapters", "research",
"researcher" ,"researchers" ,"study", "studies",
"studied", "studys", "studying", "one", "two", "three")
abstracts_corp <- tm_map(abstracts_corp, removeWords, myStopwords)
abstracts_corp <- tm_map(abstracts_corp, stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, stemDocument)
abstracts_corp[[1]]$content
abstracts_dtm <- DocumentTermMatrix(abstracts_corp)
abstracts_dtm
inspect(abstracts_dtm[1, ])
inspect(abstracts_dtm[, "risk"])
head(Terms(abstracts_dtm))
mat_abstract_words <- as.matrix(abstracts_dtm)
dim(mat_abstract_words)
mat_abstract_words[1:5, 1:5]
sum(mat_abstract_words[1, ] > 0)
burnin <- 200 # number of omitted Gibbs iterations at beginning
iter <- 3000 # number of iterations
thin <- 2000 # number of omitted iterations between each kept iteration
seed <- list(2003, 5,63, 100001, 765) #seeds to enable reproducibility
nstart <- 5 # number of repeated random starts
best <- TRUE # only continue model on the best model
k <- 5
ldaOut <- LDA(x = abstracts_dtm, k = k, method = "Gibbs",
control=list(nstart = nstart, seed = seed, best = best,
burnin = burnin, iter = iter, thin = thin))
ldaOut_topics <- topics(ldaOut)
head(ldaOut_topics)
topicProbabilities <- ldaOut@gamma
head(topicProbabilities)
ldaOut_terms <- terms(ldaOut, 10)
ldaOut_terms
fitmodel <- FindTopicsNumber(dtm = abstracts_dtm,
topics = seq(from = 4, to = 40, by = 2),
metrics = c("CaoJuan2009", "Arun2010"),
method = "Gibbs",
control = list(nstart = 1, seed = c(30),
best = best, burnin = burnin,
iter = iter, thin = thin),
mc.cores = 2,  verbose = TRUE)
fitmodel
FindTopicsNumber_plot(fitmodel)
k <- 30
ldaOut2 <- LDA(x = abstracts_dtm, k = k, method = "Gibbs",
control = list(nstart = nstart, seed = seed, best = best,
burnin = burnin, iter = iter, thin = thin))
ldaOut_terms2 <- terms(ldaOut2, 10)
ldaOut_terms2[, c(2, 14, 20, 23, 24)]
library(igraph)
mat_abstract_words[1:5, 1:5]
ldaOut_topics2 <- topics(ldaOut2)
in_20_23 <- ldaOut_topics2 %in% c(20, 23)
mat_abstract_words_subset <- mat_abstract_words[in_20_23, ]
worduse <- colSums(mat_abstract_words_subset)
mat_abstract_words_subset <- mat_abstract_words_subset [, worduse > 5]
dim(mat_abstract_words_subset)
abstract_word_net <- graph_from_incidence_matrix(mat_abstract_words_subset,
mode = "all", weighted = T)
type <- vertex_attr(abstract_word_net, "type")
table(type)
V(abstract_word_net)$color[type == TRUE] <- rgb(red = 0, green = 1,
blue = 0, alpha = .2)
in20 <- names(which(ldaOut_topics2 == 20))
in23 <- names(which(ldaOut_topics2 == 23))
which_topic20 <- V(abstract_word_net)$name %in% in20
V(abstract_word_net)$color[which_topic20] <- rgb(red = 0, green = 0,
blue = 1, alpha = .2)
which_topic23 <- V(abstract_word_net)$name %in% in23
V(abstract_word_net)$color[which_topic23] <- rgb(red = 1, green = 0,
blue = 0, alpha = .2)
V(abstract_word_net)$label <- V(abstract_word_net)$name
V(abstract_word_net)$label.color <- rgb(0, 0, .2, .85)
V(abstract_word_net)$label.cex <- .75
V(abstract_word_net)$size <- 3
V(abstract_word_net)$frame.color <- V(abstract_word_net)$color
E(abstract_word_net)$color <- rgb(.5, .5, .5, .04)
set.seed(106)
plot(abstract_word_net, layout = layout_with_fr)
#install.packages("CAinterprTools")
library(CAinterprTools)
#install.packages("plot3D")
#library(plot3D)
library(FactoMineR)
library(factoextra)
library(gplots)
#library(plot3D)
library(NbClust)
url1 <- "https://github.com/JeffreyAlanSmith/Integrated_Network_Science/raw/master/data/department_topic_data.txt"
department_topic <- read.table(file = url1, header = T)
department_topic[1:4, 1:4]
dim(department_topic)
department_names <- rownames(department_topic)
topic_names <- colnames(department_topic)
ca_mod1 <- CA(X = department_topic, graph = FALSE)
ca_mod1
summary(ca_mod1, nb.dec = 2, nbelements = 5, ncp = 3)
fviz_ca_biplot(ca_mod1)
fviz_ca_biplot(ca_mod1, col.row = "orange", col.col = "steelblue",
labelsize = 3, repel = T) +
theme_minimal()
fviz_ca_row(ca_mod1, col.row = "orange", labelsize = 3, repel = T) +
theme_minimal()
eig <- get_eigenvalue(ca_mod1)
eig
fviz_screeplot(ca_mod1)
aver.rule(department_topic)
malinvaud(department_topic)
locs_department <- ca_mod1$row$coord
fviz_contrib(ca_mod1, choice = "row", axes = 1) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
fviz_contrib(ca_mod1, choice = "row", axes = 2) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
fviz_contrib(ca_mod1, choice = "col", axes = 1) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
fviz_contrib(ca_mod1, choice = "col", axes = 2) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
fviz_ca_biplot(ca_mod1, col.row = "contrib", col.col ="contrib",
labelsize = 3, repel = T) +
scale_color_gradient2(low = "white", mid = "steelblue",
high = "darkblue", midpoint = 8) +
theme_minimal()
locs_topic <- ca_mod1$col$coord
locs <- rbind(locs_department, locs_topic)
locs <- locs[, 1:2]
d <- dist(locs, method = "euclidean")
fit <- hclust(d, method = "ward.D2")
clusters <- NbClust(data = NULL, diss = d, distance = NULL,
method = "ward.D2", index = c("silhouette"))
clusters$Best.nc
cluster_names <- paste("cluster", clusters$Best.partition, sep = "")
names(cluster_names) <- names(clusters$Best.partition)
row_clusters <- cluster_names[department_names]
col_clusters <- cluster_names[topic_names]
fviz_ca_biplot(ca_mod1, col.row = row_clusters, col.col = col_clusters,
labelsize = 3, repel = T) +
theme_minimal()
ca_mod2 <- CA(department_topic, ncp = 2, graph = FALSE)
clust_rows <- HCPC(res = ca_mod2, nb.clust = 8,  graph = FALSE,
cluster.CA = "rows")
clust_cols <- HCPC(res = ca_mod2, nb.clust = 8,  graph = FALSE,
cluster.CA = "columns")
plot(clust_rows, choice = "map", draw.tree = FALSE)
row_clusters2 <- clust_rows$data[department_names, "clust"]
table(row_clusters, row_clusters2)
plot(clust_cols, choice = "map", draw.tree = FALSE)
url1 <- "https://github.com/JeffreyAlanSmith/Integrated_Network_Science/raw/master/data/sociologysample.csv"
abstracts <- read.csv(file = url1, stringsAsFactors = FALSE)
head(abstracts)
library(NLP)          # basic processing of natural language
library(tm)           # text mining package
library(SnowballC)    # word stemming package
library(topicmodels)  # package for modeling the topics
library(ldatuning)    # package for evaluating the models
abstracts_corp <- Corpus(VectorSource(abstracts$text))
length(abstracts_corp)
abstracts_corp <- tm_map(abstracts_corp, tolower)
gsub_function <- function(x, pattern) gsub(pattern, replacement = " ", x)
split_words <- content_transformer(gsub_function)
abstracts_corp <- tm_map(abstracts_corp, split_words, pattern = "_")
abstracts_corp <- tm_map(abstracts_corp, split_words, pattern = "/")
abstracts_corp <- tm_map(abstracts_corp, removePunctuation)
abstracts_corp <- tm_map(abstracts_corp, removeNumbers)
abstracts_corp <- tm_map(abstracts_corp, removeWords, stopwords("english"))
myStopwords <- c("dissertation", "chapter", "chapters", "research",
"researcher" ,"researchers" ,"study", "studies",
"studied", "studys", "studying", "one", "two", "three")
abstracts_corp <- tm_map(abstracts_corp, removeWords, myStopwords)
abstracts_corp <- tm_map(abstracts_corp, stripWhitespace)
abstracts_corp <- tm_map(abstracts_corp, stemDocument)
abstracts_dtm <- DocumentTermMatrix(abstracts_corp)
mat_abstract_words <- as.matrix(abstracts_dtm)
mat_abstract_words[1:5, 1:5]
burnin <- 200 # number of omitted Gibbs iterations at beginning
iter <- 3000 # number of iterations.
thin <- 2000 # number of omitted iterations between each kept iteration
seed <- list(2003, 5,63, 100001, 765) #seeds to enable reproducibility
nstart <- 5 # number of repeated random starts
best <- TRUE # only continue model on the best model
k <- 5
ldaOut <- LDA(x = abstracts_dtm, k = k, method = "Gibbs",
control=list(nstart = nstart, seed = seed, best = best,
burnin = burnin, iter = iter, thin = thin))
ldaOut_topics <- topics(ldaOut)
topicProbabilities <- ldaOut@gamma
ldaOut_terms <- terms(ldaOut, 10)
fitmodel <- FindTopicsNumber(dtm = abstracts_dtm,
topics = seq(from = 4, to = 40, by = 2),
metrics = c("CaoJuan2009", "Arun2010"),
method = "Gibbs",
control = list(nstart = 1, seed = c(30),
best = best, burnin = burnin,
iter = iter, thin = thin),
mc.cores = 2,  verbose = TRUE)
FindTopicsNumber_plot(fitmodel)
k <- 30
ldaOut2 <- LDA(x = abstracts_dtm, k = k, method = "Gibbs",
control = list(nstart = nstart, seed = seed, best = best,
burnin = burnin, iter = iter, thin = thin))
ldaOut_terms2 <- terms(ldaOut2, 10)
ldaOut_terms2[, c(2, 14, 20, 23, 24)]
# extract the topic number which have highest probability among all topics
topics(ldaOut2)
library(igraph)
ldaOut_topics2 <- topics(ldaOut2)
in_20_23 <- ldaOut_topics2 %in% c(20, 23)
mat_abstract_words_subset <- mat_abstract_words[in_20_23, ]
worduse <- colSums(mat_abstract_words_subset)
mat_abstract_words_subset <- mat_abstract_words_subset [, worduse > 5]
abstract_word_net <- graph_from_biadjacency_matrix(mat_abstract_words_subset,
mode = "all", weighted = T)
type <- vertex_attr(abstract_word_net, "type")
table(type)
V(abstract_word_net)$color[type == TRUE] <- rgb(red = 0, green = 1,
blue = 0, alpha = .2)
in20 <- names(which(ldaOut_topics2 == 20))
in23 <- names(which(ldaOut_topics2 == 23))
which_topic20 <- V(abstract_word_net)$name %in% in20
V(abstract_word_net)$color[which_topic20] <- rgb(red = 0, green = 0,
blue = 1, alpha = .2)
which_topic23 <- V(abstract_word_net)$name %in% in23
V(abstract_word_net)$color[which_topic23] <- rgb(red = 1, green = 0,
blue = 0, alpha = .2)
V(abstract_word_net)$label <- V(abstract_word_net)$name
V(abstract_word_net)$label.color <- rgb(0, 0, .2, .85)
#V(abstract_word_net)$label.cex <- .75
V(abstract_word_net)$size <- 3
V(abstract_word_net)$frame.color <- V(abstract_word_net)$color
E(abstract_word_net)$color <- rgb(.5, .5, .5, .04)
set.seed(106)
plot(abstract_word_net, layout = layout_with_fr)
legend("topleft",
legend = c("Topic 20 (Family-related abstract)",
"Topic 23 (Gender-related abstract)",
"Word nodes (terms)"),
col = c(rgb(0,0,1,0.6), rgb(1,0,0,0.6), rgb(0,1,0,0.6)),
pch = 19,
pt.cex = 1.5,
bty = "n",
cex = 0.9)
library(CAinterprTools)
library(FactoMineR)
library(factoextra)
library(gplots)
library(NbClust)
url1 <- "https://github.com/JeffreyAlanSmith/Integrated_Network_Science/raw/master/data/department_topic_data.txt"
department_topic <- read.table(file = url1, header = T)
department_topic[1:4, 1:4]
department_names <- rownames(department_topic)
topic_names <- colnames(department_topic)
ca_mod1 <- CA(X = department_topic, graph = FALSE)
fviz_ca_biplot(ca_mod1, col.row = "orange", col.col = "steelblue",
labelsize = 3, repel = T) +
theme_minimal()+
scale_color_manual(
name = "",  # 범례 제목
values = c("orange", "steelblue"),
labels = c("Department", "Topic")
)
fviz_contrib(ca_mod1, choice = "col", axes = 1) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
fviz_contrib(ca_mod1, choice = "col", axes = 2) +
theme(axis.text.x = element_text(size = 8.0, angle = 75))
p <- fviz_ca_biplot(
ca_mod1,
labelsize = 3,
repel = TRUE
)
p +
scale_color_manual(
name = "Type",
values = c("Department" = "orange", "Topic" = "steelblue")
) +
theme_minimal()
fviz_ca_biplot(ca_mod1, col.row = "orange", col.col = "steelblue",
labelsize = 3, repel = T) +
theme_minimal()+
scale_color_manual(
name = "Label",
values = c("orange", "steelblue"),
labels = c("Department", "Topic")
)
p <- fviz_ca_biplot(
ca_mod1,
col.row = "orange",
col.col = "steelblue",
labelsize = 3,
repel = TRUE
) +
theme_minimal()
p + annotate("text", x = -1.2, y = 1.2, label = "● Department", color = "orange", size = 3.5, hjust = 0) +
annotate("text", x = -1.2, y = 1.1, label = "● Topic", color = "steelblue", size = 3.5, hjust = 0)
p <- fviz_ca_biplot(
ca_mod1,
col.row = "orange",
col.col = "steelblue",
labelsize = 3,
repel = TRUE
) +
theme_minimal()
p + annotate("text", x = -1.2, y = 1.2, label = "● Department", color = "orange", size = 3.5, hjust = 0) +
annotate("text", x = -1.2, y = 1.1, label = "▲ Topic", color = "steelblue", size = 3.5, hjust = 0)
p <- fviz_ca_biplot(
ca_mod1,
col.row = "orange",
col.col = "steelblue",
labelsize = 3,
repel = TRUE
) +
theme_minimal()
p + annotate("text", x = -1, y = 1.2, label = "● Department", color = "orange", size = 3.5, hjust = 0) +
annotate("text", x = -1, y = 1.1, label = "▲ Topic", color = "steelblue", size = 3.5, hjust = 0)
p <- fviz_ca_biplot(
ca_mod1,
col.row = "orange",
col.col = "steelblue",
labelsize = 3,
repel = TRUE
) +
theme_minimal()
p + annotate("text", x = -0.8, y = 1.2, label = "● Department", color = "orange", size = 3.5, hjust = 0) +
annotate("text", x = -0.8, y = 1.1, label = "▲ Topic", color = "steelblue", size = 3.5, hjust = 0)
p <- fviz_ca_biplot(
ca_mod1,
col.row = "orange",
col.col = "steelblue",
labelsize = 3,
repel = TRUE
) +
theme_minimal()
p + annotate("text", x = -0.8, y = 0.8, label = "● Department", color = "orange", size = 3.5, hjust = 0) +
annotate("text", x = -0.8, y = 0.7, label = "▲ Topic", color = "steelblue", size = 3.5, hjust = 0)
